%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:

There are other projects, previous and current, that attempt to solve the same
or similar problems as we are with \thename{}. Here we present the ones we find
most interesting and from which we have drawn inspiration.

\subsection{Parrot VM}

The Parrot Virtual Machine\footnote{\url{http://www.parrot.org}} is a project
that attempts to solve similar issues as \thename{}. Most importantly almost solely
focuses on efficient support of dynamically typed languages. Moreover it aims to
provide very flexible interoperability between any language ported to Parrot; as
the docs say: ``In theory, you will be able to write a class in Perl, subclass
it in Python and then instantiate and use that subclass in a Tcl
program.''\cite{parrot-docs}.

An interesting aspect of Parrot is that it completely hides the lowest-level
representation of executable code, called Parrot Bytecode (PBC), which is what
the virtual machine ultimately executes. Instead various layers of abstraction
are provided to ease the task of generating and reading code. One level above
PBC there is Parrot Assembly (PASM) which is more akin to regular assembly, and
provides little to no syntactic sugar. A level further up the abstraction
hierarchy there is Parrot Intermediate Representation (PIR), that is the main
language of interaction with Parrot, whether for code generating by a compiler
or authored by human beings. Compared to other interface languages for abstract
machines, it is a high-level language with constructs such as conditional
control structures, infix operators (e.g. \texttt{=}, \texttt{>},
\texttt{\&\&}), local variable and parameter declarations (effectively hiding
calling convention mechanisms), and even classes.

This hierarchy of abstraction makes it easy to port language implementations to
Parrot because a lot of the boilerplate code (calling conventions, variable
declarations, etc.) is hidden, and if fine-grained control is required PASM is
available.

Parrot uses the so-called Polymorphic Container (PMC) type that is, as the name
suggest, a polymorphic type theoretically capable of holding any type of
data. They are however by design object-oriented and class like, because
``languages that are built on top of Parrot are typically
object-oriented''\cite{parrot-docs}. A set of common PMCs are provided by
Parrot, but new ones can be implemented using a super set of C (as to ensure
efficiency).

What Parrot does not provide is an efficient platform for statically typed
languages. For instance, it offers no support for storing and retrieving type
information, which is a very significant shortcoming in terms of statically
optimized dispatches.

In summary Parrot is to dynamically typed languages, what JVM and CLR are for
statically typed languages. That means it does not bridge the gap between the
two, but merely provides facilities for the dynamic (and mostly object-oriented)
paradigm.

\subsection{JVM's \texttt{invokedynamic}}

From its inception in 1996\cite{java-1.0-press} the JVM was a very statically
typed system that did not provide any support for dynamic languages. With its
rising popularity several non-Java languages were made available for
it. Scala\footnote{\url{http://www.scala-lang.org}} and
Groovy\footnote{\url{http://groovy-lang.org}} were among the first
\textit{dynamic} languages that were designed to be run on the JVM. They handled
dynamic typing and dispatch by ``[including] wrapper type classes, using hash
tables to provide dynamic symbol resolution, and so on''\cite{friesen14}.

The Da Vinci Machine Project\cite{da-vinci} was an effort to solve the issue of
implementing dynamic language features on the JVM. It was adopted in Java 7 in
2011, with the most essential addition (in terms of dynamic language support)
being the \texttt{invokedynamic} Java Bytecode instruction. Previous to
\texttt{invokedynamic} a caller had to know the fully qualified name and type
signature of a method that it wanted to dispatch to.

With \texttt{invokedynamic} and by use of so-called method handles, it is
possible to defer the look-up of the dispatch target to run-time and do it by
providing either a class object (for static methods) or a class instance (for
instance methods) along with the types of arguments that are given. A method
handle is comparable to what is known as a function pointer in
C\cite{friesen14}, i.e. something that designates a callable entity to which
dispatches (or invocation) can be made. A method handle is looked up during
run-time. Because a method can be looked up not only by the type of the object
on which it resides, but also by the type of the arguments that it accepts, that
naturally enables \term{multimethods}, which is similar to method overloading
with the significant difference of relying on the types of arguments given
rather than the static type of the object.

%TODO: clearer and more

\subsection{Dynamic Language Runtime and Roslyn Compiler}
% Compiler-as-a-Service
%% Also exposed API see http://stackoverflow.com/questions/7852926/microsoft-roslyn-vs-codedom
% LINQ expression trees https://msdn.microsoft.com/en-us/library/bb882637.aspx
% Interaction with other language (IronRuby, IronPython, etc. SCSS compiler was ``ported'')
% btw DLR is dead

The Dynamic Language Runtime~\cite{dlr} was developed by Microsoft and ran on
top of the Dynamic Language Runtime. It provided support for several dynamic
language features such as a dynamic type system, method dispatch and code
generation.

When handling method calls in a dynamic language, the machine is forced to do
some extra look-ups to find the correct method, as it is unable to statically
deduce which function is to be used. This creates some overhead and can easily
make the running time of dynamic languages slow. DLR remedies this by using
dynamic call sites with method caching. This technique is often referred to as
inline caching, where the results of a method look-ups are stored in an limited
data-structure. This saves the machine of many consecutive look-ups. This
optimization technique was first developed by Smalltalk 80~\cite{deutsch}.

Dynamic types are handled by the meta class {\tt DynamicMetaObject}. These
classes provide dynamic functionality to objects by having several virtual
methods handling setting, getting and method invocation. DLR offers even higher
abstraction and convenience with the two sub-classes {\tt DynamicObject} and
{\tt ExpandoObject}. Methods include {\tt TryCreateInstance} and {\tt
  TryInvoke}.

Through the .NET Framework, DLR was used by popular implementations of dynamic
languages, such as Python and Ruby, named
IronPython~\footnote{\url{http://ironpython.net/}} and
IronRuby~\footnote{\url{http://ironruby.net/}}. The development of DLR has been
discontinued since 2010. According to a former Microsoft developer, this has to
do with Microsoft's lack of commitment towards dynamic
languages~\cite{schementi}\cite{cooper}. In spite of this, as a result of being
in the .NET Framework, DLR has made its way into the new Roslyn compiler.

Most compilers are `black-boxed`, where one gives the compiler some source code
and it either gives you an executable or a list of errors, with little say on
how or what happens inside the compiler. The Roslyn compiler is a complete
rewrite of the C\# and Visual Basic (VB) compilers, opening the `black-box`. It
now exposes APIs to central components of the compiler, such as the parser,
symbol table, language binders and the intermediate language emitter (code
generation). This gives the programmer vasts amounts of flexibility and enables
him/her of parsing code, doing different kinds of analysis and evaluating code
dynamically. The latter is a valuable tool when doing meta-programming,
i.e. programs writing programs.
