\subsubsection{Control Flow}
\label{sec:implementation:instr:control-flow}

At its core control flow is about changing the program counter of an executing
thread. The program counter, also known as the instruction pointer, is an
unsigned integral value representing an address in the byte code where the
machine will start parsing the next instruction. Instructions can change the
value of the program counter during execution which is the basis of all control
flow instructions, including branching and sub-routine calls.

The program counter is implemented as a field on the thread state and since the
thread state is the fundamental argument to all instruction functions, it is
trivial to change the program counter at any time. Because the byte code
programs are byte \textit{addressed} and most instructions span several bytes,
it is possible to set the program counter to a byte that is in the middle of an
instruction, which would lead to unpredictable unwanted behavior. Assemblers
usually use named labels that mark specific locations in assembly code and are
converted to actual addresses when assembled into binary format. It could also
be a task of the byte code verifier to assert that addresses always point to the
beginning of an instruction (as described in
Section~\ref{sec:separate-components:verifier:branch}).

Branching is the most fundamental control flow operation and is implemented
simply by setting the executing thread's program counter directly. Certain
checks are made to verify that a given address is a legal branch target.

Sub-routines are essentially implemented in the exact same way as branching
operations but with the addition of an activation element being pushed to the
stack. The activation element contains the address of the call site which is
used to set the program counter back when a return instruction is executed. In
addition to being on the stack, pointers to activation elements are saved as a
linked list in the thread state making it possible to retrieve its information
without having to search through the stack. Among others, it is used to check
whether the program counter is exceeding the address bounds of the current
sub-routine, which will result in an implicit return.

\subsubsection{Prefixes and Suffixes}

Instructions can be prefixed or suffixed to modify the behavior of certain
instructions.
%TODO note om large prefix

The {\tt noOverflow} prefix signals the machine to throw exceptions if overflow
occurs when executing the following arithmetic instruction. Overflow is detected
differently for the various arithmetic operations and operand types. This is
required as different as types have different maximum and minimum values. We
will briefly explain the challenge of handling overflow in different scenarios
and how \thename{} currently, and imperfectly, tackles them.

Looking at how to detect overflow when doing arithmetic operations on {\em
  signed integer} operands, we have to take the size of the the operands' type
into account. For instance, an {\tt Int8} can only represent integer numbers in
the rage of -128 to 127. Knowing the type's maximum and minimum value, we can
deduce whether the operation will induce over- or underflow on operand $a$ and
$b$. In the case where the operation is addition, we check if operand $b$ is
larger than zero {\em and} operand $a$ is lesser than the sum of the type's
maximum value and $b$'s inverse. This can be denoted in the following formula:

\label{eq:overflow}
\begin{equation}
  overflow = (b > 0) \wedge (a > max - b)
\end{equation}

In a similar fashion we can detect underflow by:

\begin{equation}
  underflow = (b < 0) \wedge (a < min - b)
\end{equation}

If the operation is subtraction, we just change the plus operator to minus, in
the two equations. In the case of multiplication we use division, etc.

For unsigned integers the case is a little simpler, as the operand cannot be
negative. Therefore, when doing addition, underflow can per definition not
occur:

\begin{equation}
  a + b > 0, \qquad when\ a > 0, b > 0
\end{equation}

For substitution, we only needs to check if the $b$ operand is greater
than $a$, which will result in a negative number, thus inducing underflow.

\begin{equation}
  a - b < 0, \qquad when\ a > 0, b > a
\end{equation}

These fairly simple solutions has shown through tests, to work well where the
operand precision is not {\tt Int64} or {\tt UInt64}. The reason for this is
that all overflow check function promote each operand to an {\tt int64\_t} or
{\tt uint64\_t}, which prevents overflow of all operands with lower
precision. In the case of 64-bit integers, there is a risk of the check itself
to overflow. More precisely, $a < min - b$ will overflow if $b$ is
positive. There is not good solution for this, other than to use a higher
precision number for the tests. As C does not have any built-in data types of
larger precision, one would have to use multi-precision numbers which would
require some time to implement. We have chosen to note the short comings of the
current solution and focus our attention else where.

Both GCC and Clang has built-in functions for doing integer arithmetic while
also detecting
overflow~\footnote{\url{https://gcc.gnu.org/onlinedocs/gcc/Integer-Overflow-Builtins.html}}\footnote{http://clang.llvm.org/docs/LanguageExtensions.html\#checked-arithmetic-builtins}. GCC's
implementation does this by converting the two operands into infinite precision
numbers, where after doing the the operation on the promoted operands. The
result is then cast to the original precision. If the casted result does not
equal the infinite precision result, overflow has occurred, which is indicated
by the functions return value. We have chosen to not use these to hold the
implementation as library independent as possible.

Detecting overflow for floating-point precision numbers is somewhat more
challenging, due to the more complex nature of its encoding. The C Standard
Library has built-in constants for finding a float's maximum value; {\tt
  FLT\_MIN} and {\tt FLT\_MAX} for single precision, {\tt DBL\_MIN} and {\tt
  DBL\_MAX} for double precision. These could in theory be used in the same
fashion as above, creating an efficient solution, given that we could do
built-in arithmetic operations on them. This is unfortunately not true, as {\tt
  FLT\_MAX - 1}, for instance, is regarded as undefined behavior and will on
most platforms be equal to {\tt FLT\_MAX}. Inducing undefined behavior when
trying to deduce whether an instruction is safe, renders its point
moot. %TODO lidt forvirrende. watfix?

We have therefore chosen to use a simple but also sub-optimal solution. When,
for instance, adding two floats together that should produce overflow, the
resulting value will become equal to {\tt FLT\_MAX} (in the case of single
precision). We therefore check whether the result of each operation either
equals the maximum or minimum value for the given precision. In cases where an
operation equals exactly the maximum or minimum value, an overflow exception
will be thrown, even though under- or overflow might not have occurred.

\subsubsection{Arithmetic}

The arithmetic operations we have implemented is addition, substitution,
multiplication, division, remainder and negation. With the exception of the
latter, these are all binary operations, used through reverse-polish notation,
or suffix notation. We have made use of C's build in operators to make this as
efficient as possible. As the machine enforces strong typing, an exception will
be thrown if the operands are not of the same type. The only exception is if the
operand is of {\tt AnyType}, where it will automatically be converted to a
matching type.

Different types have to be handled differently to ensure correct
computations. For instance, an integer type cannot be used in the same way as a
floating-point number. To do this, we interpret the operands to its
corresponding C built-in type, perform the operation, and converting them back
to its standard machine type. We cannot rely on GCC to cast the types directly,
as this would be platform dependent; different platform use different endianness
and standards for storing number in memory.

These binary arithmetic operations are very similar in implementation, so we
have chosen to use C macros to keep the code base tidy, and not have to repeat
our selves. In summary this macro does the following:

\begin{enumerate}
  \item Ensure the top two stack elements are of the same type or {\tt AnyType}
  \item Pop them off the stack
  \item Align the types if either is {\tt AnyType}
  \item Allocate space for the result
  \item Decode the operands to their corresponding C type
  \item Perform the arithmetic operation
  \item If the {\tt noOverflow} prefix is set, check for overflow
  \item Encode result back to machine type
  \item Push the result to the stack
\end{enumerate}

The saturated variants of the arithmetic instructions are implemented by
checking whether an overflow or underflow will occur in which case the value is
bounded within the limits of the given type.
%TODO it's not really

% TODO: markus link with design fluent that shit
Logical operations include {\tt and}, {\tt or}, {\tt xor}, {\tt not}, and left-
and right-wise bit-shift ({\tt shl} and {\tt shr}) (TODO: {\tt ashr}). With the
exception of {\tt not}, their corresponding instructions are implemented in a
similar fashion as the arithmetic, through a macro, using C's built-in
operators. The {\tt not} instruction takes a {\tt Boolean} value, which is
either {\tt 0x00} or {\tt 0x01}, and flips its value.

In addition we also have two sets of compare instructions, either comparing two
numeric operands of matching type or comparing a single numeric operand to zero
(or null). Each category includes equals, lesser-than and greater-than
instructions, all of which push a {\tt Boolean} result value to the stack.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:
