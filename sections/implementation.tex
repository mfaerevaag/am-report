%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:

\subsection{Tools and Languages}

% vi bruger C cause yolo and speed and control++
% vi bruger gcc
% vi bruger gdb omg
% vi bruger doxy dauda se appendix wow

% notes: not all code snippets correspond directly to the implementation to
% avoid unnecessary details


\subsection{Core Infrastructure}

The infrastructure of \thename{} is the code that lays the basis for interaction
between the individual parts of the system. It is a collection of machinery
which hand control back and forth between each other, such as the instruction
cycle, thread management and exception handling. Besides the machine's exposed
exception handling system there is an internal error handling mechanism which
allows errors within the machine to be handled as gracefully.

\subsubsection{Instruction Cycle}

The fundamental means of operation in the machine is the execution of
instructions parsed and interpreted from byte code. Each thread runs their own
cycle, the essence of which is shown in
Listing~\ref{lst:implementation:instruction-cycle}

\begin{lstlisting}[%
  caption={Pseudo representation of the instruction cycle},%
  label={lst:implementation:instruction-cycle}]
while (machine is running) {
  fetch opcode
  fetch potential arguments
  execute instruction corresponding to opcode
  update program counter
}
\end{lstlisting}


% vm initialization
% instruction cycle
% memory layout (stack per thread, heap area, code area)
% thread

% Very general architecture (theres a vm, a file reader, instruction codes, etc)
% What's in the VM state and Thread state?
% How code bytes are handled
% Instruction cycles
% Internal error handling
% Logging/debugging facilities
% Graceful exits / clean up
% Command line arguments

\subsection{Stacks}

A stack is in itself a fairly simple construction that allows values to be
pushed to an popped from an allocated memory region. Stack elements are stored
and retrieved by the Last In, First Out principle.

\subsubsection{Stack elements}

Each element on a stack holds information about both the \textit{declared} and
\textit{actual} type of data that it contains. Details on this is described in
\ref{NEEDED}. The data is a simple array of bytes, stored in big endian order,
i.e. the most significant bit is at the lowest memory address.

\subsubsection{Memory Layout}

Arguably the most intuitive way to construct a stack is to use a simple array of
a fixed initial size and handle operations by keeping track of the number of
elements in the stack. A push operation thus increments the number of elements
and assigns a value to the new top-most slot. A pop operation will
correspondingly decrement the number of elements in the stack and potentially
return the element that is being removed. When the number of elements in the
stack exceeds the initial size of the containing array more memory must be
allocated. This can be done simply by use of \code{realloc} where the common
approach is to double the amount of allocated memory, to adapt to quickly
growing stacks. However, \code{realloc} can be a performance issue because it
will create a new allocation, copy over the current data and free the old
allocation\cite{man-realloc} which arguably is an expensive operation. Since the
stack is by far the most frequently used means of operation in \thename{} it is
critical that it performs well.

Another important thing to consider is that the content of a stack element
depends on the type of the element, and thus have varying sizes. An element
whose type is \code{Int8} requires a single byte for storage while an element of
type \code{Int32} requires 4 bytes of storage. Since we do not want to waste
memory on redundant bytes, that prevents us from implementing stack elements as
fixed size structures laid out in an array as described above. We have solved
the problem by implementing stack elements as a singly linked list going from
the top element down to the bottom. The memory used by the stack should be
contiguous, to avoid a large amount of allocations and deallocations, thus the
elements in the linked list must all reside one after another in memory. The
actual content of an element is stored \textit{in between} the linked list
nodes, and the \code{next} pointer simply points to the memory address following
its content data bytes (if there is another element following
it). Figure~\ref{fig:implementation:stack:element} shows how the stack elements
are laid out.

The C language does not support variable length arrays, which means that an
array must have its length declared, otherwise the type is regarded as
incomplete. However, line~\ref{code:stack-element:flexible-data} in
Listing~\ref{lst:implementation:stack:element} shows feature known as
\code{flexible array} that allows the last field of a struct to be declared as a
size-less array. We take advantage of exactly that so that we can easily
interpret the \code{data} field of an element as an array of bytes.

What is left to solve is the problem of a stack growing beyond its initial
size. As mentioned, reallocation of the memory used by the stack works, but
results in poor performance. To mitigate the issue we have modelled the stack as
a linked list of allocated memory regions which we call \textit{segments}. Each
segment is essentially a stack in itself and is implemented exactly as described
above. The benefit is that when a segment becomes full, a new segment is simply
allocated and wired into the linked list, thus preventing the need for a
reallocation. The exposed interface of the stack consists of a set of stack
operation functions that essentially maps operations onto segments by selecting
the appropriate segment, and potentially what index of its elements that will be
the target of a given operation. Thus the segments are hidden in the
implementation and are solely internal data structures which users need not know
of.

\begin{remark}
  Segmented stacks is not a novel idea. They are used by the Go programming
  language to facilitate large amounts of unbounded stacks (for so-called
  goroutines). The Rust programming language did as well but later abandoned
  them. There are arguments for not using them because of the overhead generated
  by extra work needed when stack limits are
  exceeded\cite{rust:segmented-stack, go:segmented-stack}.
\end{remark}

Segments are implemented as a doubly linked list as shown in
listing~\ref{lst:implementation:stack:segment}. Each segment keeps track of its
length (i.e.~number of elements current in the segment) and the top element. The
\code{content} field is the region allocated for storage of elements. The
\code{data\_cursor} is maintained to always point to the byte following the top
element's content bytes and is useful when pushing a new element. The
\code{size} field simply represents the size of the memory region allocated for
the segment and is used to check whether the segment has room for more elements.

\begin{figure}[h]
  \centering
  \begin{subfigure}[a]{.49\textwidth}
    \begin{lstlisting}[language={[ANSI]C},%
  caption={Structure defining the stack},%
  label={lst:implementation:stack:element}]
struct stack_element {
    struct stack_element_s *next;

    int actual_type;
    int declared_type;

    byte data[]; (*@\label{code:stack-element:flexible-data}@*)
}
    \end{lstlisting}
  \end{subfigure}
  \begin{subfigure}[a]{.49\textwidth}
    \begin{lstlisting}[language={[ANSI]C},%
  caption={Structure defining a segment of the stack},%
  label={lst:implementation:stack:segment}]
struct stack_segment_s {
    int size;
    int length;

    stack_element *head;

    void *content;
    char *data_cursor;

    struct stack_segment_s *next;
    struct stack_segment_s *prev;
}
    \end{lstlisting}
  \end{subfigure}
\end{figure}

A segment has a limited number of slots for elements but the stack itself is
unbounded as a result of the segment list; there is no limit to how many
segments can be allocated, except the amount of physical or virtual memory
available to the machine.

\subsubsection{Administering Memory Usage}

A new segment is allocated when the last active segment becomes full, but is not
immediately freed when it becomes empty. Instead a number of segments are cached
to facilitate series of stack operations that operate right between the limit of
two segments. Consider a loop of code that repeatedly pushes four elements to
the stack only to pop them off moments after. If there are two slots left in the
last segment when the loop begins, a new segment must be allocated during the
course of one loop iteration. However when the iteration pops the values off
again the new segment will become empty, which without the cached segments would
result in the segment being freed. With the cached segments the newly allocated
segment is saved and is simply rewired into the stack when it is needed again.
% TODO: this could be further optimized by detecting such loops and
% increasing the size of the current chunk. aint nobody got time for
% that.

When there are more inactive segments than defined by
\code{STACK\_NUM\_CACHED\_SEGMENTS} a segment will be freed. This is trivial
because all of the segments and its elements' data lies within the region
pointed to by \code{content}, so it is simply freed.

\subsubsection{Stack element structure}
% TODO: write when confirmed
% TODO: all ops run O(1) amortized, except freeing

\begin{figure}[H]
  \centering
  \input{figures/stack-layout}
  \caption{Stack memory layout}
\end{figure}

\subsubsection{Operations}

Stack operations are implemented as functions with a \code{stack\_} prefix and
their first parameter is a pointer to the stack on which the operation is to be
performed. To give sense of how it works in practice,
Listing~\ref{lst:implementation:stack:operations} shows the source code for the
\code{push} operation.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language={[ANSI]C},
  caption={Source code of the \code{push} stack operation},
  label={lst:implementation:stack:operations}]
void stack_push(stack *s, stack_element *se)
{
    if (stack_will_overflow(s, se)) { (*@\label{code:stack-push:will-overflow}@*)
        stack_segment *old_seg = s->last_segment;
        se->next = old_seg->head; (*@\label{code:stack-push:link-segments}@*)

        stack_push_segment(s);
    }

    stack_segment_push_element(s->last_segment, se);
}
\end{lstlisting}
\end{minipage}

Line~\ref{code:stack-push:will-overflow} makes sure that there is room for the
stack element in the current segment. If there is not a new segment is created
and the \code{next} pointer of the new element is linked to the last element of
the previous segment so that the elements are in principle a single linked
list. The element is then pushed onto the segment.

\subsection{Execution Model}


\subsection{Heap Objects}

\begin{figure}[H]
  \centering
  \input{figures/heap-object-layout}
  \caption{Heap object memory layout}
\end{figure}


\subsection{Threading}
% Abstraction
% Structure (tree)
%% Main thread

To support concurrent programming fundamental mechanisms of threading has to be
supported. These include creating and destroying threads while also having
synchronization structures for mutual exclusion, such as mutexes.

We have done this by wrapping existing implementations of threading libraries.
This way we can easily change the threading back-end by choosing which library
wrapper to be compiled with the executable. The interface for threads will
therefor be the same, regardless of which library is handling the logic.

The thread interface is defines in {\tt thread.h}, while the back-ends will live
in {\tt thread\_<lib>.c}.

The abstract machine itself utilizes threading by always running programs
through threads. That way, all error will safely be handled without crashing the
main process. This is paramount, as machine crashes are considered critical
errors and should never occur.

Threads will be structured in a tree fashion, where a thread can spawn multiple
child threads.
% TODO: update
\begin{ccode}
struct thread_state {
    struct thread_state *parent;
    struct thread_state *children;

    void *thread;

    uint32_t pc;
    stack_t stack;

    ...
};
\end{ccode}

As shown above, each thread state has a void pointer called {\tt thread}
(TODO). This is used by the chosen threading library, where itself needs to
create the necessary structures and track the data. This will likely consist of
some internal thread identifier and possible mutex variables.


\subsection{Binary file}

% Assembler
%% Simple parsing/emitting
%% Label calculations (offsets)

% Stack based
%% Elements are (type, value) pairs
%% Dynamically sized elements
%%% Linked list

% Object model
%% Virtual tables
%% (Un)boxing

% Execution model
%% Single stack
%% Return values as output arguments
%% No frame pointer(?)

% Binary format (ELF)
%% Sections
%% Type encoding
%% Instructions
%%% Argument encoding

% Exception handling

% Debugging information

\subsection{Analysis}
% Valgrind
% gprof?

\subsection{Testing}

% Test-Driven Development (not strictly)
% unit tests
% black box testing
% def. terms

Throughout the project we have made heavy use of testing to ensure the
correctness of the implementation, i.e. whether it strictly follows the machine
specification~\ref{sec:spec}. We have both made use of \term{unit}- and
\term{integration-tests}. Here unit-tests have the purpose of testing a single
isolated component, typically a function. Here we mock a specific state of the
machine, or the state of a component in the machine, and then run isolated
functions where we {\it know} what the result should be, for which we can easily
test. By comparison, the integration-tests have a much larger scope. Their
purpose is to test the whole program without any regard to any specific
component. This effectively ensures each component is wired together correctly.

For parts of the implementation we have made use of \term{test-driven
  development} (TDD). Here we write the tests prior to implementing the actual
functionality being tested. This eliminates the danger of false positives, where
tests pass when they are not supposed to. It also offers an efficient work flow,
where the minimum functionality is implemented to make the tests pass.

\subsubsection{Unit-tests}
Unit-testing in C is a fairly simple process and essentially does not require
any framework or library. While not required, a simple set of \term{macros} will
greatly improve the readability and ease of writing tests.

% cmocka
In spite of this, we have chosen to use a unit-testing library called {\it
  cmocka}~\cite{cmocka}. It is a well tested and documented library, also used
by large projects like {\it libssh}~\footnote{Implementation of the SSH protocol:
  \url{http://libssh.org/}}. It offers several features which makes unit-testing
more powerful and simpler to write. For instance, it offers test suites and
\term{mocking} of objects which enabled us to set up a specific state of the
machine. With this state, we can run isolated tests, manipulating the state and
thereafter checking that the correct transformations and output has occurred.

Cmocka also allows the test program to recover from signaled exceptions,
e.g. {\tt SIGSEGV}, {\tt SIGILL}, etc. If a test in the test program triggers a
segmentation fault exception, for instance, it will not exit, but rather show
where the exception occurred and print useful debugging information like the
call stack.

Lastly, the library works on a wide range of platform and only requires the use
of the C library. This makes it possible to use the library on embedded
platforms and with different compilers.

% example
As an example, we will describe how we test parts of the stack implementation.

Firstly, we create a mocked state of a stack which we can use for our tests.
\begin{lstlisting}[language={[ANSI]C},caption={Unit-test setup procedure}]
  static int setup(void **state)
  {
    stack_t *s = malloc(sizeof(stack_t));
    stack_init(s, 100);

    assert_non_null(s->elements);
    assert_int_equal(100, s->max_size);
    assert_int_equal(0, sum_stack(s));

    *state = s;

    return 0;
  }
\end{lstlisting}

In the above code listing, we initialize a stack object, do some
simple assertions, and store it in the {\tt state} variable passed
with the setup function. As we see below, this state is given as
argument to all test cases which easily allows us to retrieve it by
dereferencing.
\begin{lstlisting}[language={[ANSI]C},caption={Unit-test of {\tt stack\_pop}}]
  static void test_pop(void **state)
  {
    stack_t *s = *state;

    uint32_t sum = sum_stack(s);

    stack_push(s, make_se_int(1));
    stack_push(s, make_se_int(2));
    stack_push(s, make_se_int(3));

    assert_int_equal(3, SE_INT(stack_pop(s)));
    assert_int_equal(2, SE_INT(stack_pop(s)));
    assert_int_equal(1, SE_INT(stack_pop(s)));

    assert_int_equal(sum, sum_stack(s));
  }
\end{lstlisting}

After having retrieved the stack for the {\tt state} parameter, we create an XOR
sum of the stack. When having tested the specific function, we assert that the
new XOR sum is the same as before, making sure that there is no unexpected
changes to the stack. Due to the simple nature of our {\tt stack\_sum} function,
this is not a guarantee, as different states of the stack may compute the same
sum. % TODO: more on stack sum?
In the body of our test case, the {\tt stack\_pop} function in this case, we
push several elements to the stack and assert that they are popped off again in
the correct order.

After all test cases has completed, a teardown function is run, reversing that
of the setup function. In the case of the stack tests, it simply frees the
memory allocated to the state of the stack.
% \begin{lstlisting}[language={[ANSI]C},caption={Unit-test teardown procedure}]
%   static int teardown(void **state)
%   {
%   stack_t *s = *state;
%   stack_free(s);
%
%   return 0;
% }
% \end{lstlisting}


\subsubsection{Integration-tests}
We want our integration tests to test the implementation in the fashion of
black-box testing, i.e. given some input, the program should produce a specific
output, regardless of how the program works internally. The easiest way of
accomplishing this is by taking the actual machine executable and running it
with certain programs and arguments. We have therefor created several different
programs, from which we know the desired output.

As an example we can check that the machine fails when stack underflow occurs,
i.e. popping more values off the stack then there are actual values. A program
doing exactly this could be:
% TODO: update with actual
\begin{lstlisting}[language={bytecode},caption={Machine program producing
    stack underflow}]
  fn main
  {
    pop
  }
\end{lstlisting}

The above machine program will try to pop an element off the stack without there
being any elements, producing a stack underflow error. We can test the output of
the machine by both asserting the exit code of the process, where we will have
specified the meanings of different exit codes, and by asserting what is written
to standard out and error ({\tt stdout} and {\tt stderr}). In the case of stack
underflow the exit code should be 4 and the output should match `underflow`
(TODO: update).

To automate this process we use shell scripting. For convenience, we have chosen
to utilize a shell testing framework (that's right), called {\tt
  shUnit2}~\footnote{shUnit2, unit testing for shell scripts:
  \url{http://code.google.com/p/shunit2/}}. This lets us streamline the
integration testing process, in contrast of manually running each machine
program and checking the output.

shUnit2 enables us to have an alias for the actual machine binary, letting us
set the target binary through our build system and piping standard error to
standard out. In our test cases we can then, by using the alias, store the
output and exit code in variables and do assertions based on their expected
values.
% TODO: update return code
\begin{lstlisting}[language={sh},caption={shUnit2 underflow test case}]
  test_stack_underflow()
  {
    output=$(am --file ${PDIR}/underflow.amb)
    ret=$?

    assertEquals "return code should be 4" 4 $ret
    assertTrue "output should include underflow" \
    "contains \"$output\" \"underflow\""
  }
\end{lstlisting}

In the above test case we run the machine with the underflow program, asserting
that the process exits with the correct code and that the output contains the
word `underflow`.
