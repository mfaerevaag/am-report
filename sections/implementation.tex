\subsection{Tools and Languages}

We have implemented \thename{} in the C programming language, more specifically
using the C99 standard with GNU extensions by use of GCC\footnote{The GNU
  Compiler Collection: \url{https://gcc.gnu.org}}. There are both pros and cons
of using a relatively low-level language (as compared to other available
languages), but we found that the benefits outweighed the disadvantages.

First of all C is extremely portable; GCC is available on \textit{a lot} of
architectures, and all modern operating systems ship with a C compiler which
essentially is all that is required to build \thename{} for a new platform. The
standard libraries and architecture specific functions available differ with
each machine and device, so we aim at relying on as few external libraries as
possible and provide wrappers for the ones we use so that the implementation can
be ported quickly.

Secondly we do not want to rely on a garbage collector provided by languages
like C++ and Java. We need to full control over where each bit of data is
stored, mostly for performance reasons both in terms of memory footprint and
execution speed.

Third, speed is of the essence and C is notoriously fast, given that the code is
well-written.

There are however downsides to using C. Because we are not veterans of C and due
to its low-level nature it is inherently more difficult to develop features that
could be implemented in a few lines of code in a higher-level language, and
memory has to be tracked meticulously to prevent memory leaks. We have found
that it is a great exercise for becoming proficient with programming in general
because it provides us with knowledge of the mechanisms that lie behind concepts
that are generally taken for granted.

For finding such memory leaks we use Valgrind~\footnote{Valgrind:
  \url{http://valgrind.org/}}, and for profiling and benchmarking we use GNU
gprof~\footnote{GNU gprof:
  \url{https://sourceware.org/binutils/docs/gprof/}}. We have made use of shell
scripts for automating benchmarking, and in turn the R programming
language~\footnote{R Programming Language: ~\url{http://www.r-project.org/}} for
doing statistical analysis on the generated results.

For debugging we use gdb via GNU Emacs~\footnote{GNU Emacs:
  \url{http://www.gnu.org/software/emacs}} and for analyzing memory usage and
fixing memory leaks we use the Valgrind instrumentation tool\footnote{Valgrind:
  \url{http://valgrind.org}}.

The code is extensively documented using Doxygen~\footnote{Doxygen:
  \url{http://www.stack.nl/~dimitri/doxygen}} style comments.

\textbf{Note:} The code snippets presented in the following sections does not
always correspond directly with the code found in the actual
implementation. They carry the gist of what we want to communicate but generally
avoids unnecessary and redundant information not relevant to the individual
cases.

\subsection{Code Style}

The C languages frees the programmer to structure code and data in about as many
ways as one can imagine. This can be both a blessing and a curse, and warrants
some agreed upon conventions to maximize consistency.

For a module of functionality we use a general pattern that consists of a struct
containing the state or data of a piece of machinery, and corresponding prefixed
functions that take such a structure as argument and operate on its
data. Stacks, for instance, are implemented with a \code{stack} struct, and the
functions \code{stack\_init}, \code{stack\_pop}, \code{stack\_free}, etc. This
essentially mimics object orientation from other languages (C++, Java), but has
the benefit of most functions being \term{pure}, i.e.~a function that only
depends on its input, making testing and reasoning about the code easier.

We use a few naming conventions that will be present in the code as well as code
snippets found in this thesis: %TODO might be useless

\begin{itemize}
\item We use underscore to separate multi-word variable and function names.
\item Structs are defined with \code{\_s} suffix and typedef'd to a name
  without.\\Eg: \code{struct stack\_s \{...\}} and \code{typedef struct stack\_s
    stack}.
\item Enums are defined with \code{\_e} suffix and typedef'd to a name
  without.\\Eg: \code{struct opcode\_e \{...\}} and \code{typedef enum opcode\_e
    opcode}.
\end{itemize}

\subsection{Core Infrastructure}
\label{sec:implementation:core}

% Very general architecture (theres a vm, a file reader, instruction codes, etc)
% What's in the VM state and Thread state?
% How code bytes are handled
% Instruction cycles
% Internal error handling
% Logging/debugging facilities
% Graceful exits / clean up
% Command line arguments

% thread
% instructions
% stack
% types
% gc interface
% symtab, strtab, ttable

The infrastructure of \thename{} is the code that lays the basis for interaction
between the individual parts of the system. It is a collection of machinery
which hand control back and forth between each other, such as the instruction
cycle, thread management and exception handling. Besides the machine's exposed
exception handling system there is an internal error handling mechanism which
allows errors within the machine to be handled as gracefully possible.

The machine is divided into several modules of which \code{am}, for abstract
machine and implemented in \code{am.h/c}, is the most overarching. It defines a
structure, the \code{am\_state} struct, which contains data that is generally
available in a machine-wide context. We say ``generally'' because some parts of
the system are by design ignorant of their context. A string table, for
instance, is not aware of which thread is using it, and instructions do not know
of the abstract machine state. The most important members of \code{am\_state}
are a pointer to the code bytes and a pointer to the main thread. The state is
initialized by loading in the code %TODO

During the initialization phase of the machine approximately the following steps
are carried out, in order: %TODO

\begin{enumerate}
\item Parse command-line arguments
\item Set up internal error handling mechanisms
\item Initialize global abstract machine state
  \begin{enumerate}
  \item Load byte code from the executable
  \item Load information tables %TODO not really
  \end{enumerate}
\item Initialize root scope
  \begin{enumerate}
  \item Load the the run-time library functions
  \end{enumerate}
\item Initialize main thread
  \begin{enumerate}
  \item Allocate stack
  \end{enumerate}
\item Begin the instruction cycle in the main thread
\end{enumerate}

We will briefly explain each step in the following sections.

\subsubsection{Command-line Arguments}
\thename{} will eventually be run through an executable binary, most likely in a
command-line environment. The most common, and arguably the most efficient, way
of customizing parameters and execution options is through command-line
arguments, given directly to the executable when run. These arguments can be
extended to do a number of things, but essentially we only require the name of
the binary file to be executed and optionally customizing the level of
verbosity, i.e. the amount of logging information to display.

We follow common conventions by having two special arguments for displaying
useful meta information about the \thename{} binary. These include the {\tt
  --help} argument for printing information on the different arguments, and {\tt
  --version}, for simply printing the version of the binary.

For ease of implementation we use the Getopt library~\footnote{Getopt (libc):
  \url{http://www.gnu.org/software/libc/manual/html_node/Getopt.html}}, included
in C's Standard Library.

%TODO args for the executable

\subsubsection{Internal Error Handling}
% Why
% Error handler
% Signals
% Cleanup
% Error macro

When writing software, history has shown that bugs will most likely find its way
into the code. The do not expect \thename{} to be an exception, so rather than
denying this fact, we try to remedy the situation by gracefully exiting the
program, while also trying to some useful information on what went wrong. This
way makes it easier for users to understand what is going on and reporting the
problem so it can fixed.

Internal errors can occur two ways. Either by the machine checking the value of
different parameters, ensuring they are of the expected format, in which the
they are not we can cowardly stop the machine without crashing. Or an error can
occur by the operating system signaling the machine that it is trying to do
something illegal. In this we can catch the signal, which follows the
POSIX-standard, and again gracefully exit the program.

When we say gracefully exit, we mean that we can stop running threads, free any
allocated memory, print some information and set the return code of the
process. The two last things are very important to let the user know what has
happened, but also to debug the problem.

With checks, errors can be invoked through a special logging macro {\tt
  log\_err}, described in the \nameref{sec:implementation:core:debug} section
below.

\subsubsection{ELF File Loading}
The first thing the machine does upon start up is to load the input file that is
going to be executed. The current implementation does not read information
tables which means that only the byte code is loaded. Information table entries
can be hardcoded into the system easily, which is what we have done for testing
purposes.

In the \code{loader} module, we use the library Libelf\footnote{libelf:
  \url{https://directory.fsf.org/wiki/Libelf}} to parse and extract data from
the input file. It provides the means to very easily parse ELF files and search
through segments and sections, making the process of byte code loading quite
simple indeed. The file is verified to be a valid, parsable ELF file before
beginning any data extraction. Libelf exposes a function a to get the section
following another by use of which the sections are iterated. We need to extract
the data of the \code{.text} section which is where the byte code is stored in
its entirety. Thus for each section we simply check its name and if it matches
we copy the bytes from the section into the abstract machine state's code field.

\subsubsection{Instruction Cycle}
% general loop (check with whats in design)
% instruction functions signature
% role of instructions vs vm (who fetches what)
% byte code address is into elf, ie offset from first byte when loaded

The fundamental means of operation in the machine is the execution of
instructions that are parsed and interpreted from byte code. Each thread runs
their own cycle, the essence of which is shown in
Listing~\ref{lst:implementation:instruction-cycle}

\begin{lstlisting}[%
  caption={Pseudo representation of the instruction cycle},%
  label={lst:implementation:instruction-cycle}]
while (thread is running) {
  fetch opcode
  fetch potential arguments
  execute instruction corresponding to opcode
  update program counter
}
\end{lstlisting}

Each task is performed by different modules of the machine. The abstract
machine, \code{am}, module is responsible for reading byte code including
reading the opcodes, parsing arguments and in turn executing the function that
implements the individual functions. The instruction module,
\code{instruction.h/c} is where instruction routines are defined, one function
per instruction. All instruction functions take a \code{thread\_state*} argument
that they use to manipulate the stack, change the program counter, access scopes
and so on. Generally the abstact machine does not do look ups into information
tables and other logic, rather its responsibility is to read and parse the byte
code and delegate the rest of the work to other modules.

As an example consider the following byte code stream:

%TODO needs correct opcode value
\code{0: 0xFC, 1: 0x10, 2: 0x00, 3: 0x00, 4: 0x05, 5: 0x39, ...}

And let the program counter be $pc = 0$. The machine will carry out the following:

\begin{enumerate}
\item Read instruction prefixes
  \label{item:read-prefix}
  \begin{enumerate}
  \item Look for bytes that are valid prefix values which is any value greater
    than or equal to \code{0xFC} (decimal 252).
  \item The byte at $pc=0$, \code{0xFC}, is a valid prefix, namely the
    \code{large} prefix.
  \item Set the \code{pre\_large} flag in the executing thread's state and
    increment program count, $pc \leftarrow pc + 1 \Rightarrow pc= 1$
  \item The byte at $pc=1$, \code{0x10}, is not a valid prefix, thus stop
    reading prefixes.
  \end{enumerate}

\item Read the opcode which is always a single byte. The byte at $pc=1$ is
  \code{0x10} which corresponds to the \instr{pushConstant} instruction.

\item Increment program counter, $pc \leftarrow pc + 1 \Rightarrow pc = 2$

\item Fetch arguments
  \begin{enumerate}
  \item \instr{pushConstant} takes an argument, an integer value representing a
    constant table index.
  \item The \code{pre\_large} flag is true, so we must read the argument as a
    32-bit (four bytes) integer.
  \item Interpret the next four bytes as a big endian integral value. The four
    bytes are \code{0x00, 0x00, 0x05, 0x39} which is interpreted as the value
    \code{0x539} (decimal 1337).
  \item Increment program counter by four bytes,
    $pc \leftarrow pc + 4 \Rightarrow pc = 6$
  \end{enumerate}

\item Call the instruction function for \instr{pushConstant} with the argument
  $1337$.

\item Go to~\ref{item:read-prefix}.

\end{enumerate}

The implementation of concrete instructions is detailed in
Section~\ref{sec:implementation:instr}.

\subsubsection{Logging and Debugging}
\label{sec:implementation:core:debug}
% Logging macros
% Debug functions (print\_stack)
% Debug instructions

\thename{} has a logging system, found in the {\tt logger.h} module. It handles
all messages sent by all components of the machine and decides whether to print
them to {\tt stdout}. This decision is based on a logging level, which is part
of the global state of the machine. The logging level sets the `barrier` for
which a message should be printed. The levels includes {\tt brief}, {\tt normal}
and {\tt verbose} which can be customized through command-line arguments, but
defaults to {\tt normal}. As each log message is also categorized with a level,
the logging module decides, given the current logging level, if it should be
printed. The message level are {\tt error}, {\tt warning} and {\tt info}.

If the logging level is set to brief, only warnings will be printed, if set to
normal, warnings will also be printed, and lastly, is set to verbose, everything
will be printed.

A log message is sent through an interface of macros, exposed by the {\tt
  logger.h} header-file. Each message level has two logging macros, logging a
message of the given level. The two macros include on which takes a string, and
one, suffixed with `f`, which takes a formatted string and a variable number of
arguments.
\begin{ccode}
#define log_warn(msg)                             \
  do {                                            \
      if (should_log(WARNING)) {                  \
          fprintf(stderr, "warning: " msg "\n");  \
      }                                           \
  } while (0)
\end{ccode}

The {\tt log\_err} macro, will in addition to log an error, clean up and stop the
machine, as it cannot safely continue.

For debugging during development there are an extra macro for printing a message
prefixed with file name, function name and line number. In addition the is one
suffixes with `f`, which takes a formatted string in the same manner as the
logging macros.

The logging messages are only displayed if the {\tt DEBUG} macro value is
defined. This value is automatically set through the build system, if not making
a release build through the {\tt release} target.


\subsection{Stacks}
\label{sec:implementation:stacks}
\input{sections/implementation-stack}
% vm initialization
% instruction cycle
% memory layout (stack per thread, heap area, code area)
% thread


\subsection{Execution Model}
% \label{sec:implementation:execmodel}
% \input{sections/implementation-execmodel}


\subsection{Information Tables}
\label{sec:implementation:infotables}
The three information tables handled by \thename{} are all implemented in the
most simplistic way possible, with the intention being; less is more. With that
being said, this might not be as apparent with the meta table, than with the
string- and constants table. As for the reasons explained in TODO.

The constants- and string table are almost identical in implementation. They are
both parsed from the executable file, where they are stored as static lists of
elements. This means we can parse the size of each list and allocate internal
arrays of the same size and type. The type for the internal string table will
simply be a list strings, or rather {\tt char *}'s, as they are encoded as
Modified UTF-8, which are null-byte terminated. As for the constants table, they
are stored as simple arrays of bytes. It is the compilers job of keeping track
of the bytes' encoding. Therefore, the same constant can be interpreted as
different numbers, depending on the type it is expected to have.

For parsing bytes to numbers, as signed and unsigned integers, and
floating-point numbers, there are special utility functions located in the {\tt
  byte.h} module. These are extensively tested for overflow, sign errors,
endianness errors and other common pitfalls when decoding numbers to C's
built-in types. In total there are 26 unit tests, all located in the module's
respective test suite, found in {\tt test/byte\_test.c}. The test suite are kept
dry by using macros to generate tests for a multiple of edge cases. For more
information on how we decode more complex encoding, as floating-point precision
numbers, see section~\ref{sec:implementation:meta:types}.

Each element in the constants- and string table are parsed lazily. If we were to
parse both tables on initialization, it would create an undesirable overhead,
depending on their size. To encapsulate this, each table has lookup function
which checks if the element on the given index is {\tt NULL}, in which case it
is first parsed from the executable and stored in the internal table. Due to the
fact that we did not have time to finish the assembler, the data not currently
being parsed from the executable, but rather taken from hardcoded test data. The
interface is on the other hand is set, encapsulating the code which needs to be
changed.

The metadata table is a little more complex and therefor requires a more complex
implementation. This is due to the design of the meta information system,
explained in section~\ref{sec:implementation:meta}. Unfortunately, due to the
same reasons as with the constant and string tables, this has not been
implemented. Also, as with above, the interface is, it just returns hardcoded
test data instead of parsing anything from an executable.


\subsection{Heap Objects}


\subsection{Threading}
% Abstraction
% Structure (tree)
%% Main thread

To support concurrent programming fundamental mechanisms of threading has to be
supported. These include creating and destroying threads while also having
synchronization structures for mutual exclusion, such as mutexes.

We have done this by wrapping existing implementations of threading libraries.
This way we can easily change the threading back-end by choosing which library
wrapper to be compiled with the executable. The interface for threads will
therefor be the same, regardless of which library is handling the logic.

The thread interface is defines in {\tt thread.h}, while the back-ends will live
in {\tt thread\_<lib>.c}.

The abstract machine itself utilizes threading by always running programs
through threads. That way, all errors will safely be handled without crashing
the main process. This is paramount, as machine crashes are considered critical
errors and should never occur.

Threads will be structured in a tree fashion, where a thread can spawn multiple
child threads.
% TODO: update
\begin{ccode}
struct thread_state {
    struct thread_state *parent;
    struct thread_state *children;

    void *thread;

    uint32_t pc;
    stack_t stack;

    ...
};
\end{ccode}

As shown above, each thread state has a void pointer called {\tt thread}
(TODO). This is used by the chosen threading library, where itself needs to
create the necessary structures and track the data. This will likely consist of
some internal thread identifier and possible mutex variables.

\subsection{Meta Information}
\label{sec:implementation:meta}
\input{sections/implementation-meta}

\subsection{Scopes}

Scopes are implemented as an array of key-value pairs that we call symbols, in
which the key is a string and the value is a function pointer. Obviously, the
value of a symbol should be an arbitrary type, as almost anything should be
storable in a symbol, but so far we have only used scopes to implement the
run-time library and thus have not made a generic symbol implementation. Name
resolution in a scope is carried out by iterating the array of symbols and
comparing names with the name that is being searched for. This is simple and
inefficient but sufficient for small test programs.

The obviously superior implementation would be a hash map, where a symbol's
names is hashed into an integer and stored in an array indexed by the hashed
value of the name. This requires an array that is as large as the output of the
hash function which is likely to be unacceptable since most hash functions
compute at least 32-bit meaning resulting in a 4.4 billion long array. Instead
the desired size of array is chosen, $n$, and the hash keys are computed
$\mod n$ to find the index. It is possible for two different names to have the
same $\mod$'d value, called a collision. To mitigate this each entry in the
array is a linked list of symbols that also stores the full hash value. As a
result, if a collision occurs it is possible to iterate the linked list and find
the symbol that matches the full hash.

\subsection{Instructions}
\label{sec:implementation:instr}
\input{sections/implementation-instr}

\subsection{Run-Time Library}

The run-time library is implemented in the \code{runtime\_lib} module as a
collection of functions, one for each available run-time function. There are
currently two functions available namely \code{push\_scope} and \code{iprint}
which pushes a scope onto the current one and prints an integer value from the
stack, respectively.

\subsection{Testing}
\input{sections/implementation-testing}

% Assembler
%% Simple parsing/emitting
%% Label calculations (offsets)

% Object model
%% Virtual tables
%% (Un)boxing

% Execution model
%% Single stack
%% Return values as output arguments
%% No frame pointer(?)

% Binary format (ELF)
%% Sections
%% Type encoding
%% Instructions
%%% Argument encoding

% Exception handling

% Debugging information

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:
