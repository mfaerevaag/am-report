\subsection{Tools and Languages}

We have implemented \thename{} in the C Programming Language, more specifically
using the C99 standard with GNU extensions by use of GCC\cite{gnu:gcc}. There
are both pros and cons of using a relatively low-level language (as compared to
other available languages), but we found that the benefits outweighed the
disadvantages.

First of all C is extremely portable; GCC is available on \textit{a lot} of
architectures, and all modern operating systems ship with a C compiler which
essentially is all that is required to build \thename{} for a new platform. The
standard libraries and architecture specific functions available differ with
each machine and device, so we aim at relying on as few external libraries as
possible and provide wrappers for the ones we use so that the implementation can
be ported easily.

Secondly we do not want to rely on a garbage collector provided by languages
like C++ and Java. We need full control over where each bit of data is stored,
mostly for performance reasons both in terms of memory footprint and execution
speed.

Third, speed is of the essence and C is notoriously fast, given that the code is
well-written.

There are however downsides to using C. Because we are not veterans of C and due
to its low-level nature it is inherently more difficult to develop features that
could be implemented in a few lines of code in a higher-level language, and
memory has to be tracked meticulously to prevent memory leaks. We have found
that it is a great exercise for becoming proficient with programming in general
because it provides us with knowledge of the mechanisms that lie behind concepts
that are generally taken for granted.

\textbf{Note:} The code snippets presented in the following sections do not
always correspond directly with the code found in the actual
implementation. They carry the gist of what we want to communicate but generally
avoids unnecessary and redundant information not relevant to the individual
cases.

\subsection{Code Style}

The C languages liberates the programmer to structure code and data in about as
many ways as one can imagine. This can be both a blessing and a curse, and
warrants some agreed upon conventions to maintain consistency.

For a module of functionality we use a general pattern that consists of a struct
containing the state or data of a piece of machinery, and corresponding prefixed
functions that take such a structure as argument and operate on its
data. Stacks, for instance, are implemented with a \code{stack} struct, and the
functions \code{stack\_init}, \code{stack\_pop}, \code{stack\_free}, etc. This
essentially mimics object orientation from other languages (C++, Java), but has
the benefit of most functions being pure, i.e.~a function that only depends on
its input, making testing and reasoning about the code easier.

\subsection{Core Infrastructure}
\label{sec:implementation:core}

The infrastructure of \thename{} is the code that lays the basis for interaction
between the individual parts of the system. It is a collection of machinery
which hand control back and forth between each other, such as the instruction
cycle, thread management and exception handling. Besides the machine's exposed
exception handling system there is an internal error handling system which
allows errors within the machine to be handled as gracefully possible.

The implementation of the machine is divided into several modules each of which
serve a specific purpose. Figure~\ref{fig:implementation:arch} shows the
overarching architecture and which modules depend on each other.

The \textit{Engine} module is the top-most control unit that is used to set
everything in motion. It only implements two functions; \code{start} which
initializes the other components and begins execution, and \code{stop} that
frees the resources claimed by the machine and exits gracefully. The
\textit{Abstract Machine} module is responsible for reading the byte code,
parsing it into opcodes, instruction prefixes and argument values and
subsequently delegating the work to the \textit{Instruction Executer}. That is
where the guts of the system lies and where all program logic is performed. It
manipulates the stack through the \textit{Stack} module which implements the
data structures and exposes an interface for pushing, popping, replacing and
peeking into those. The \textit{Information Tables} modules is really three
modules, one for each of the string, constant and metadata table which are all
interfaces to global tables with functions to look up entries by various
criteria. The \textit{Garbage Collector} is the interface to the memory managing
unit, and is responsible for allocating memory on the heap and automatically
releasing it when it is no longer in use. Finally, the \textit{Thread} module
handles creation and destruction of threads in which all program code is
executed.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figures/arch}
  \caption{The architecture of \thename{}. An arrow represents a dependency
    where the module pointed \emph{from} depends on the module pointed
    \emph{to}.}
  \label{fig:implementation:arch}
\end{figure}

During the initialization phase the machine carries out approximately the
following steps:

\begin{enumerate}
\item Parse command-line arguments
\item Set up internal error handling mechanisms
\item Initialize the global abstract machine state
\item Parse the input executable file
  \begin{enumerate}
  \item Load byte code from the executable
  \item Load information tables (not implemented)
  \end{enumerate}
\item Initialize scope
  \begin{enumerate}
  \item Create an implicit root scope, ancestor to all future scopes
  \item Load the the run-time library functions into the root scope
  \end{enumerate}
\item Initialize main thread
  \begin{enumerate}
  \item Allocate a thread
  \item Allocate a stack for it
  \end{enumerate}
\item Begin the instruction cycle in the main thread
\end{enumerate}

The following sections details how the above steps are performed.

\subsubsection{Command-line Arguments}
The common way, and arguably the only way the makes sense, of customizing the
parameters of an executable is through command-line arguments, given directly to
the executable when run. These arguments can be extended to do a number of
things, but essentially we only require the name of the binary file to be
executed and optionally customizing the level of verbosity, i.e.\ the amount of
logging information to display.

The input file is set with the {\tt --file} (or {\tt -f}) argument, and the
verbosity level is set with either {\tt --brief} ({\tt -b}) or {\tt --versbose}
({\tt -v}). For more information on logging, see
Section~\ref{sec:implementation:core:debug} below.

We follow common conventions by having two special arguments for displaying
useful meta information about the \thename{} binary. These include the {\tt
  --help} argument for printing information on the different arguments, and {\tt
  --version}, for simply printing the version of the binary.

For ease of implementation we use the Getopt library\footnote{Getopt (libc):
  \url{http://www.gnu.org/software/libc/manual/html_node/Getopt.html}}, included
in C's Standard Library.

\subsubsection{Internal Error Handling}

When writing software, history has shown that bugs are unavoidable, and we do
not expect \thename{} to be an exception. Rather than denying this fact, we try
to remedy the situation by gracefully exiting the program, while also trying to
give some useful information about what went wrong. This makes it easier for
users to understand what is going on and reporting the problem so it can fixed.

Internal errors can occur in two ways. Either by the machine checking the value
of different parameters, ensuring they are of the expected format, and if they
are not we can cowardly stop the machine without crashing. The other scenario is
an error occuring by the operating system signaling the machine that it is
trying to do something illegal. In this we can catch the signal, which follows
the POSIX-standard, and again gracefully exit the program.

When we say gracefully exit, we mean that we can stop running threads, free any
allocated memory, print some information and set the return code of the
process. The two last things are very important to let the user know what has
happened, but also to debug the problem.

Errors can be invoked through a special logging macro {\tt log\_err}, described
in the \nameref{sec:implementation:core:debug} section
below.

\subsubsection{ELF File Loading}

The first thing the machine does upon start up is to load the input file that is
going to be executed. The current implementation does not read information
tables which means that only the byte code is loaded. Information table entries
can be hardcoded into the system easily, which is what we have done for testing
purposes.

In the \code{loader} module, we use the library Libelf\footnote{libelf:
  \url{https://directory.fsf.org/wiki/Libelf}} to parse and extract data from
the input file. It provides the means to easily parse ELF files and search
through segments and sections, making the process of byte code loading quite
simple indeed. The file is verified to be a valid, parsable ELF file before
beginning any data extraction. Libelf exposes a function to get the section
following another by use of which the sections are iterated. We need to extract
the data of the \code{.text} section which is where the byte code is stored in
its entirety. Thus for each section we simply check its name and if it matches
we copy the bytes from the section into the abstract machine state's code field.

\subsubsection{Instruction Cycle}

The fundamental means of operation in the machine is the execution of
instructions that are parsed and interpreted from byte code. Each thread runs
their own cycle, the essence of which is shown in
Listing~\ref{lst:implementation:instruction-cycle}

\begin{minipage}{\linewidth}
\begin{lstlisting}[%
  caption={Pseudo representation of the instruction cycle},%
  label={lst:implementation:instruction-cycle}]
while (thread is running) {
  fetch prefixes
  fetch opcode
  fetch potential arguments
  update program counter
  execute instruction corresponding to opcode
}
\end{lstlisting}
\end{minipage}

All instruction functions take a \code{thread\_state*} argument that they use to
manipulate the thread's stack, change the program counter, access scopes and so
on.

As an example consider the following byte code stream:

\code{0: 0xFC, 1: 0x04, 2: 0x00, 3: 0x00, 4: 0x05, 5: 0x39, ...}

And let the program counter be $pc = 0$. The machine will carry out the
following:

\begin{enumerate}
\item Read instruction prefixes
  \label{item:read-prefix}
  \begin{enumerate}
  \item Look for bytes that are valid prefix values which currently is any value
    greater than or equal to \code{0xFC} (decimal 252).
  \item The byte at $pc=0$, \code{0xFC}, is a valid prefix, namely the
    \code{large} prefix.
  \item Set the \code{pre\_large} flag in the executing thread's state and
    increment program count, $pc \leftarrow pc + 1 \Rightarrow pc= 1$
  \item The byte at $pc=1$, \code{0x04}, is not a valid prefix, thus stop
    reading prefixes.
  \end{enumerate}

\item Read the opcode which is always a single byte. The byte at $pc=1$ is
  \code{0x04} which corresponds to the \instr{pushConstant} instruction.

\item Increment program counter, $pc \leftarrow pc + 1 \Rightarrow pc = 2$

\item Fetch arguments
  \begin{enumerate}
  \item \instr{pushConstant} takes an argument, an integer value representing a
    constant table index.
  \item The \code{pre\_large} flag is true, so we must read the argument as a
    32-bit (four bytes) integer.
  \item Interpret the next four bytes as a big endian integral value. The four
    bytes are \code{0x00, 0x00, 0x05, 0x39} which is interpreted as the value
    \code{0x539} (decimal 1337).
  \item Increment program counter by four bytes,
    $pc \leftarrow pc + 4 \Rightarrow pc = 6$
  \end{enumerate}

\item Call the instruction function for \instr{pushConstant} with the argument
  $1337$.

\item Go to~\ref{item:read-prefix}.

\end{enumerate}

The implementation of concrete instructions is detailed in
Section~\ref{sec:implementation:instr}.

\subsubsection{Logging and Debugging}
\label{sec:implementation:core:debug}

\thename{} has a logging system, found in the {\tt logger.h} module. It handles
all messages sent by all components of the machine and decides whether to print
them to {\tt stdout}. This decision is based on a logging level, which is part
of the global state of the machine. The logging level sets the ``barrier'' for
when a message should be printed. The available levels includes {\tt brief},
{\tt normal} and {\tt verbose} which can be customized through command-line
arguments, but defaults to {\tt normal}. As each log message is also categorized
with a level of severity, the logging module compares the logging level and the
message level to decide whether the message should be printed. The message
levels are {\tt error}, {\tt warning} and {\tt info}.

If the logging level is set to brief, only warnings will be printed, if set to
normal, warnings will also be printed, and lastly, if set to verbose, everything
will be printed.

A log message is sent through an interface of macros, exposed by the {\tt
  logger.h} header-file. Each message level has two logging macros, logging a
message of the given severity level. The two macros include one which takes a
string, and a formatted version, suffixed with ``f'', which takes a formatted
string and a variable number of arguments (in the same fashion as
\code{printf}).

\begin{minipage}{\linewidth}
\begin{ccode}
#define log_warn(msg)                             \
  do {                                            \
      if (should_log(WARNING)) {                  \
          fprintf(stderr, "warning: " msg "\n");  \
      }                                           \
  } while (0)
\end{ccode}
\end{minipage}

The {\tt log\_err} macro, will in addition to logging an error message also
clean up and stop the machine, as it cannot safely continue. The message will be
printed to {\tt stderr} instead of {\tt stdout}, so the overlaying environment
running \thename{} can act accordingly.

For debugging during development there is two extra macros for printing a
message prefixed with file name, function name and line number. One of which is
suffixes with ``f'', denoting it takes a formatted string in the same manner as
the logging macros. The debug messages are only displayed if the {\tt DEBUG} macro value is
defined. This value is automatically set through the build system, for
convenience during development.

\subsection{Stacks}
\label{sec:implementation:stacks}
\input{sections/implementation-stack}

\subsection{Information Tables}
\label{sec:implementation:infotables}

The three information tables available in \thename{} are all implemented in the
most simplistic way possible, with the intention being; less is more. With that
being said, this might not be as apparent with the metadata table, than with the
string- and constant table. As for the reasons explained later in
Section~\ref{sec:implementation:meta}.

The constant and string table are almost identical in implementation. They are
both parsed from the executable file, where they are stored as static lists of
elements. This means we can parse the size of each list and allocate internal
arrays of the same size and type. The type for the internal string table will
simply be a list of strings, or rather {\tt char *}'s, as they are encoded as
Modified UTF-8, which are null-byte terminated. As for the constant table, they
are stored as simple arrays of bytes. It is the compilers job of keeping track
of the bytes' encoding. Therefore, the same constant can be interpreted as
different numbers, depending on the type it is expected to have.

For parsing bytes to numeric values whether as signed or unsigned integers, or
floating-point numbers, there are special utility functions located in the {\tt
  byte.h} module. These are extensively tested for overflow, sign errors,
endianness errors and other common pitfalls when decoding numbers to C's
built-in types. In total there are 26 unit tests, all located in the module's
respective test suite, found in {\tt test/byte\_test.c}. The test suites are
kept ``DRY'' by using macros to generate tests for multiple of edge cases. For
more information on how we decode more complex encoding, as floating-point
precision numbers, see Section~\ref{sec:implementation:meta:types}.

Each element in the constant and string table are parsed lazily. If we were to
parse both tables on initialization, it would create an undesirable overhead,
depending on their size. To mitigate this, each table has lookup functions which
check if the element on the given index is {\tt NULL}, in which case it is first
parsed from the executable and stored in the internal table. Currently the data
is taken from hardcoded test data, but interface is defined, encapsulating the
code which needs to be changed.

The metadata table is a little more complex and therefore requires a more
complex implementation. This is due to the design of the meta information
system, explained in Section~\ref{sec:implementation:meta}. As with above, the
interface is currently phony and just returns hardcoded test data instead of
parsing anything from an executable.

\subsection{Heap Objects}

\thename{} treats heap object as simple chunks of bytes, allocated and tracked
by the garbage collector. The only information common to all heap objects is a
type pointer describing the type of its content and thus also its size. To make
the internal data representation able to hold objects of different sizes, the
content of the object is implemented with a flexible array. Here the last
element in the internal struct is an empty array, just used a reference, or
handle, to the location of the data.

The garbage collector is responsible for making sure the following memory is
already allocated and is large enough to hold the value of its given type. As
explained later in Section~\ref{sec:separate-components:gc}, the garbage
collector has a set interface, separated from the actual implementation. With
this encapsulation, only a type is needed to get a reference to an allocated
piece of memory with the appropriate size.

Heap objects are referenced through the {\tt Reference<t>} type, where {\tt t}
is the type of the object's content.

\subsection{Threading}

To support concurrent programming fundamental mechanisms of threading has to be
supported. These include creating and destroying threads while also having
synchronization structures for mutual exclusion, such as mutexes.

We have done this by wrapping existing implementations of threading
libraries. This way we can easily change the threading back-end by choosing
which library wrapper to be compiled with the executable. The interface for
threads will therefore be the same, regardless of which library is handling the
logic.

The thread interface is defined in {\tt thread.h}, while the back-ends are
implemented in {\tt thread\_<lib>.c}. The current back-end uses the pthreads
library.

The abstract machine itself utilizes threading by always running programs
through threads. That way, all errors will safely be handled without crashing
the main process. This is paramount, as machine crashes are considered critical
errors and should never occur.

Threads are structured in a tree structure in which all threads have exactly one
parent and zero or more children. A spawned thread automatically becomes the
child of the thread that spawned it. A thread state has a \code{void*} field
that is used by the active threading library to save any library specific data
required. This will likely consist of some internal thread identifier and
possible mutex variables.

\subsection{Meta Information}
\label{sec:implementation:meta}
\input{sections/implementation-meta}

\subsection{Scopes}

Scopes are implemented as an array of key-value pairs that we call symbols, in
which the key is a string and the value is a function pointer. Obviously, the
value of a symbol should be an arbitrary type, as almost anything should be
storable in a symbol, but so far we have only used scopes to implement the
run-time library and thus have not made a generic symbol implementation. Name
resolution in a scope is carried out by iterating the array of symbols and
comparing names with the name that is being searched for. This is simple and
inefficient but sufficient for small test programs.

The obviously superior implementation would be a hash map, where a symbol's name
is hashed into an integer value and stored in an array indexed by the hashed
value of the name. This requires an array that is as large as the output of the
hash function which is likely to be unacceptable since most hash functions
compute at least 32-bit resulting in a 4.4 billion elements long array. Instead
the desired size of array is chosen, $n$, and the hash keys are computed
$\mod n$ to find the index. It is possible for two different names to have the
same $\mod$'d value, called a collision. To mitigate this each entry in the
array is a linked list of symbols that also stores the full hash value. As a
result, if a collision occurs it is possible to iterate the linked list and find
the symbol that matches the full hash.

\subsection{Instructions}
\label{sec:implementation:instr}
\input{sections/implementation-instr}

\subsection{Run-Time Library}

The run-time library is implemented in the \code{runtime\_lib} module as a
collection of functions, one for each available run-time sub-routines. There are
currently two functions available namely \code{push\_scope} and \code{iprint}
which pushes a scope onto the current one and prints an integer value from the
stack, respectively. These functions work in the same manner as regular
instruction functions in that they take a reference to a thread state and can
thus alter the stack, modify the program counter, change the heap and so on.

\subsection{Testing}
\input{sections/implementation-testing}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:
