A stack is in itself a fairly simple construction that allows values to be
pushed to an popped from an allocated memory region. Stack elements are stored
and retrieved by the Last-In, First-Out (LIFO) principle.

\subsubsection{Stack elements}

Each element on a stack holds information about both the \textit{declared} and
\textit{actual} type of data that it contains. Details on this is described in
\ref{NEEDED}. The data part of a stack element is a simple array of bytes,
stored in big endian order, i.e.~the most significant bit is at the lowest
memory address.

\subsubsection{Memory Layout}

Arguably the most intuitive way to construct a stack is to use a simple array of
a fixed initial size and handle operations by keeping track of the number of
elements in the stack. A push operation would thus increments the number of
elements and assigns a value to the new top-most slot. A pop operation will
correspondingly decrement the number of elements in the stack and potentially
return the element that is being removed. When the number of elements in the
stack exceeds the initial size of the containing array more memory must be
allocated. This can be done simply by use of \code{realloc} where the common
approach is to double the amount of allocated memory, to adapt to quickly
growing stacks. However, \code{realloc} can be a performance issue because it
will create a new allocation, copy over the current data and free the old
allocation, in the case the there is no more space directly following what is
being reallocated~\cite{man-realloc}. This is arguably an expensive operation,
and since the stack is by far the most frequently used means of operation in
\thename{}, it is critical that it performs well.
% TODO: agree ^ realloc not _always_ moves memory, but etc?

An important thing to consider is that the content of a stack element depends on
the type of the element, and thus have varying sizes. An element whose type is
\code{Int8} requires a single byte for storage while an element of type
\code{Int32} requires 4 bytes of storage and static arrays can be arbitrarily
large. Since we do not want to waste memory on redundant bytes, that prevents us
from implementing stack elements as fixed size structures laid out in an array
as described above. We have solved the problem by implementing stack elements as
a singly linked list going from the top element down to the bottom. The memory
used by the stack should be as contiguous as possible, to avoid a large amount
of allocations and deallocations, and the elements in the linked list should
reside one after another in memory. The actual content of an element is stored
\textit{in between} the linked list nodes, and the \code{next} pointer simply
points to the memory address following its content data
bytes. Figure~\ref{fig:implementation:stack-layout} shows how the stack elements
are laid out, with arrows denoting pointers.

\begin{figure}[H]
  \centering
  \input{figures/stack-layout}
  \caption{Stack memory layout}
  \label{fig:implementation:stack-layout}
\end{figure}

The C language does not support variable length arrays, which means that an
array must have its length declared, otherwise the type is regarded as
incomplete. However, line~\ref{code:stack-element:flexible-data} in
Listing~\ref{lst:implementation:stack:element} shows a feature known as a
\term{flexible array} that allows the last field of a struct to be declared as a
size-less array. We take advantage of exactly that so that we can easily
interpret the \code{data} field of an element as an array of bytes of any size.

What is left to solve is the problem of a stack growing beyond its initial
size. As mentioned, reallocation of the memory used by the stack works, but
results in poor performance. To mitigate the issue we have modelled the stack as
a linked list of allocated memory regions which we call \textit{segments}. Each
segment is essentially a stack in itself and is implemented exactly as described
above. The benefit is that when a segment becomes full, a new segment is simply
allocated and wired into the linked list, thus preventing the need for a
reallocation. The exposed interface of the stack consists of a set of stack
operation functions that essentially maps operations onto segments by selecting
the appropriate segment, and potentially what index of its elements that will be
the target of a given operation. Thus the segments are hidden in the
implementation and are solely internal data structures which users of the stack
are ignorant of.

\begin{remark}
  A segmented stack is not a novel idea. They are used by the Go programming
  language to facilitate large amounts of unbounded stacks (for concurrent
  sub-routines called goroutines). The Rust programming language did as well but
  later abandoned them. There are arguments for not using them because of the
  overhead generated by extra work needed when stack limits are
  exceeded\cite{rust:segmented-stack, go:segmented-stack}.
\end{remark}

Segments are implemented as a doubly linked list as shown in
listing~\ref{lst:implementation:stack:segment}. Each segment keeps track of its
length (i.e.~number of elements current in the segment) and the top element. The
\code{content} field is the region allocated for storage of elements. The
\code{data\_cursor} is maintained to always point to the byte following the top
element's content bytes and is useful when pushing a new element. The
\code{size} field simply represents the size of the memory region allocated for
the segment and is used to check whether the segment has room for more elements.

\begin{figure}[h]
  \centering
  \begin{lstlisting}[language={[ANSI]C},%
    caption={Structure defining the stack},%
    label={lst:implementation:stack:element}]
struct stack_element {
    /* points to next element in the upward direction */
    struct stack_element_s *next;

    int actual_type;
    int declared_type;

    byte data[]; (*@\label{code:stack-element:flexible-data}@*)
}
  \end{lstlisting}
\end{figure}

A segment has a limited amount of space for elements but the stack itself is
unbounded as a result of the segment list; there is no limit to how many
segments can be allocated, except the amount of physical or virtual memory
available to the machine.

Stack elements can be arbitrarily large. For instance fixed size arrays stored
on the stack are as large as their type indicates, and might be bigger than the
defined segment size. Thus, before pushing an element (as shown in
Listing~\ref{lst:implementation:stack:operations}) we check whether the element
can fit into a segment, and if not a segment is allocated with the size
explicitly given. The new segment is allocated the required size for the element
plus the default segment size as to allow for more elements to be pushed and
minimize the segment handling overhead.

\subsubsection{Caching Stack Segments}

A new segment is allocated when the last active segment becomes full, but is not
immediately freed when it becomes empty. Instead a number of segments are cached
to facilitate series of stack operations that operate right between the limit of
two segments. Consider a loop of code that repeatedly pushes four elements to
the stack only to pop them off moments after. If there are two slots left in the
last segment when the loop begins, a new segment must be allocated during the
course of one loop iteration. However when the iteration pops the values off
again the new segment will become empty, which without the cached segments would
result in the segment being freed. With the cached segments the newly allocated
segment is saved and is simply rewired into the stack when it is needed again.

When there are more inactive segments than defined by
\code{STACK\_NUM\_CACHED\_SEGMENTS} a segment will be freed. This is a trivial
operation because the all of the segment's data and elements' data lie within
the segment's memory allocation, so it is simply freed and there is no need to
free individual elements.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../report"
%%% End:
